{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from twython import Twython\n",
    "from collections import Counter\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RT @ImDataScientist: RT @BoozAllen: What's next for #DataScience? @KirkDBorne shares 9 key domains: https://t.co/Piaw1eww7s #DataSciBowl ht…\n",
      "Regular: What's next for DataScience?shares 9 key domains:  DataSciBowl ht…\n",
      "\n",
      "Scalable data science with R https://t.co/2SnYIg655L #feedly\n",
      "Regular: Scalable data science with R  feedly\n",
      "\n",
      "Ritesh M Srivastava, Head of Data Science at @YatraOfficial to speak at #cypher2016\n",
      "\n",
      "https://t.co/l1617mNayM https://t.co/N5J4cEyOWT\n",
      "Regular: Ritesh M Srivastava, Head of Data Science atto speak at cypher2016\n",
      "\n",
      "The \"Joel Test\" for Data Science teams: a highly irresponsible sloppy test to rate quality of teams https://t.co/RinqFvf2Gv\n",
      "Regular: The \"Joel Test\" for Data Science teams: a highly irresponsible sloppy test to rate quality of teams\n",
      "\n",
      "RT @jgcoppens: In a world where #data is power, @iMinds data scientists level the playing field https://t.co/d9JJV0OFHm #datascience #insig…\n",
      "Regular: In a world where data is power,data scientists level the playing field  datascience insig…\n",
      "\n",
      "RT @ASIDataScience: New blog post: London's most polluted parks identified by new ASI Data Science Project https://t.co/ThZHCXw4MX https://…\n",
      "Regular: New blog post: London's most polluted parks identified by new ASI Data Science Project  https://…\n",
      "\n",
      "OpenSearchNet: Data Science &amp; Crime Analysis... permanent role in #Milan JobDetailPage https://t.co/qtXTjqZwMM #beopenbehappy #osn\n",
      "Regular: OpenSearchNet: Data Science  Crime Analysis... permanent role in Milan JobDetailPage  beopenbehappy osn\n",
      "\n",
      "Data Science &amp; Crime Analysis... permanent role in #Milan JobDetailPage https://t.co/JUCrJd3Cwu\n",
      "Regular: Data Science  Crime Analysis... permanent role in Milan JobDetailPage\n",
      "\n",
      "#DataScience for #InternetofThings methodology - Evolving #CRISPDM - Part One https://t.co/6ecJfpqVhy via @datasciencectrl  #abdsc\n",
      "Regular: DataScience for InternetofThings methodology - Evolving CRISPDM - Part One   abdsc\n",
      "\n",
      "RT @MicrosoftIoT: Join us for hands-on #IoT learning at the #MSDataScience in Atlanta. Register now: https://t.co/vpc2PTvL1e https://t.co/z…\n",
      "Regular: Join us for hands-on IoT learning at the MSDataScience in Atlanta. Register now:  …\n",
      "\n"
     ]
    }
   ],
   "source": [
    "CONSUMER_KEY =\"yQDQPSOCEuJxLBkHAI18m9bQe\" \n",
    "CONSUMER_SECRET = \"BZT763KaLxPUyd0UW8PKs7M8JRvt3RUaCNvhBwwzzPoey7zmGz\"\n",
    "ACCESS_TOKEN=\"127161897-o1gC519LMaVy5GCwhdYbmK8GX8ZSSx7Sxsrd0CYl\"\n",
    "ACCESS_TOKEN_SECRET=\"oFYNdTcBQVty0jsbC437UuEocABnUmenm6rW3WmCYcGf2\"\n",
    "twitter = Twython(CONSUMER_KEY, CONSUMER_SECRET)\n",
    "\n",
    "twitter_list = []\n",
    "count = 0\n",
    "\n",
    "for status in twitter.search(q='\"data science\"')[\"statuses\"]:\n",
    "    \n",
    "    user = status[\"user\"][\"screen_name\"].encode('utf-8')\n",
    "    text = status[\"text\"].encode('utf-8')\n",
    "    \n",
    "    print(text.decode())\n",
    "    \n",
    "    p = re.compile('(http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+)|(via)?\\s(by)?\\s?@\\w+.|RT|&amp;|\\n|#|')\n",
    "    text_RE = (p.sub(\"\", text.decode())).strip()\n",
    "        \n",
    "    print(\"Regular:\", text_RE.strip())\n",
    "    print(\"\")\n",
    "    \n",
    "    if text_RE not in twitter_list:\n",
    "        \n",
    "        twitter_list.append(text_RE)\n",
    "    \n",
    "        count += 1\n",
    "        \n",
    "        f = open(\"%d.txt\" % count , 'w')\n",
    "        f.write(text_RE)\n",
    "        f.close()\n",
    "        \n",
    "    #print(\"Regular:\", text_1.strip())\n",
    "    #print(\"\")\n",
    "    \n",
    "    if len(twitter_list) == 10:\n",
    "        break\n",
    "        \n",
    "    #print(user, \":\", text)\n",
    "#     f = open(\"%d.txt\" % number , 'w')\n",
    "#     f.write(text)\n",
    "#     f.close()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "text.decode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "p = re.compile('(http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+)|(by)?\\s?@\\w+.|RT|&amp;|\\n|#|')\n",
    "\n",
    "text_1 = p.sub(\"\", text.decode())\n",
    "\n",
    "text_1.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from twython import TwythonStreamer\n",
    "\n",
    "# appending data to a global variable is pretty poor form\n",
    "# but it makes the example much simpler\n",
    "tweets = [] \n",
    "\n",
    "class MyStreamer(TwythonStreamer):\n",
    "    \"\"\"our own subclass of TwythonStreamer that specifies\n",
    "    how to interact with the stream\"\"\"\n",
    "\n",
    "    def on_success(self, data):\n",
    "        \"\"\"what do we do when twitter sends us data?\n",
    "        here data will be a Python object representing a tweet\"\"\"\n",
    "\n",
    "        # only want to collect English-language tweets\n",
    "        if data['lang'] == 'en':\n",
    "            tweets.append(data)\n",
    "            print(\"received tweet #\", len(tweets))\n",
    "\n",
    "        # stop when we've collected enough\n",
    "        if len(tweets) >= 10:\n",
    "            self.disconnect()\n",
    "\n",
    "    def on_error(self, status_code, data):\n",
    "        print(status_code, data)\n",
    "        self.disconnect()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#def call_twitter_streaming_api():\n",
    "stream = MyStreamer(CONSUMER_KEY, CONSUMER_SECRET, ACCESS_TOKEN, ACCESS_TOKEN_SECRET)\n",
    "\n",
    "    # starts consuming public statuses that contain the keyword 'data'\n",
    "    \n",
    "stream.statuses.filter(track='data')\n",
    "#stream.filter(track=['programming'])\n",
    "stream.statuses.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "top_hashtags = Counter(hashtag['text'].lower()\n",
    "                      for tweet in tweets\n",
    "                      for hashtag in tweet[\"entities\"][\"hashtags\"])\n",
    "print(top_hashtags.most_common(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
